{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"Hello World !\"'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "response = requests.get('http://127.0.0.1:8000/')\n",
        "response.text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = {'n' : 5}\n",
        "response = requests.get('http://127.0.0.1:8000/square', params=data)\n",
        "response.text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests)\n",
            "  Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl.metadata (34 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pmarie\\desktop\\interface-mistra-ai-pm\\.mistralai\\lib\\site-packages (from requests) (3.10)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests)\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl.metadata (2.3 kB)\n",
            "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "Downloading charset_normalizer-3.4.0-cp312-cp312-win_amd64.whl (102 kB)\n",
            "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Installing collected packages: urllib3, charset-normalizer, certifi, requests\n",
            "Successfully installed certifi-2024.12.14 charset-normalizer-3.4.0 requests-2.32.3 urllib3-2.2.3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install requests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Av6vcYTtyX"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Ce notebook vous guide à travers les étapes nécessaires pour installer et utiliser des modèles Mistral depuis Hugging Face et créer une API simple avec FastAPI pour générer du texte en utilisant ces modèles. Nous travaillerons avec deux modèles spécifiques :\n",
        "\n",
        "1. **Mistral-7B-Instruct-v0.3** : [Lien vers le modèle](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)  \n",
        "2. **Mistral-Nemo-Instruct-2407** : [Lien vers le modèle](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407)\n",
        "\n",
        "### Objectifs\n",
        "\n",
        "- **Créer un compte Hugging Face** : Si vous n'avez pas encore de compte, vous devrez en créer un.\n",
        "- **Générer un token d'accès Hugging Face** : Ce token est nécessaire pour télécharger et utiliser les modèles.\n",
        "- **Sélectionner et télécharger les modèles** : Nous travaillerons avec les modèles mentionnés ci-dessus.\n",
        "- **Créer une API avec FastAPI** : L'API exposera un point d'accès permettant d'interagir avec le modèle pour des tâches de génération de texte.\n",
        "\n",
        "### Aperçu du code API\n",
        "\n",
        "Voici un aperçu du code que nous allons mettre en place pour l'API. Il utilise FastAPI pour exposer un point d'accès, et la bibliothèque Transformers pour interagir avec le modèle :\n",
        "\n",
        "```python\n",
        "from fastapi import FastAPI\n",
        "from transformers import pipeline\n",
        "import uvicorn\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def index(prompt: str = \"Who are you?\"):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    response = pipe(messages)[0]['generated_text']\n",
        "    return {\"message\": response}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "```\n",
        "\n",
        "### Prérequis\n",
        "\n",
        "1. **Python installé** : Assurez-vous d'avoir Python 3.8 ou plus récent installé sur votre machine.\n",
        "2. **Installations nécessaires** : Nous utiliserons les bibliothèques suivantes :\n",
        "   - `transformers` pour interagir avec les modèles.\n",
        "   - `fastapi` pour créer l'API.\n",
        "   - `uvicorn` pour exécuter l'application.\n",
        "   - `protobuf` pour sérialiser et désérialiser des données structurées\n",
        "\n",
        "Dans les sections suivantes, nous détaillerons chaque étape pour que vous puissiez configurer votre environnement, télécharger les modèles, et exécuter votre API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlLoQBNQTtya"
      },
      "source": [
        "## Instalation de l'environement virtuel\n",
        "\n",
        "```bash\n",
        "# Créer un environnement virtuel nommé \"env\"\n",
        "python -m venv env\n",
        "\n",
        "# Activer l'environnement virtuel (Windows)\n",
        "env\\Scripts\\activate\n",
        "\n",
        "# Activer l'environnement virtuel (MacOS/Linux)\n",
        "source env/bin/activate\n",
        "```\n",
        "\n",
        "\n",
        "Pour désactiver l'environnement, utilisez la commande :\n",
        "\n",
        "```bash\n",
        "deactivate\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3AYqTPJTtyb",
        "outputId": "bf8f9a27-01fb-442d-de3e-11db56fba23d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (4.25.5)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from fastapi) (2.10.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.27.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.42.0,>=0.40.0->fastapi) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.6 starlette-0.41.3 uvicorn-0.34.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers protobuf fastapi uvicorn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FlOBpHJTtyc"
      },
      "source": [
        "#  1. **Mistral-7B-Instruct-v0.3** : [Lien vers le modèle](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxYMXe4LT7jP"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17vPa9miTtyc"
      },
      "outputs": [],
      "source": [
        "# Use a pipeline as a high-level helper : Mistral-7B-Instruct-v0.3\n",
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "pipe(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIT_fvWqTtyd"
      },
      "outputs": [],
      "source": [
        "prompt = \"Qui es-tu ?\"\n",
        "\n",
        "messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\":\n",
        "                \"Tu es un assistant spécialisé en analyse de sentiment.\"\n",
        "                \"Pour chaque texte donné, détermine si le sentiment est POSITIF, NÉGATIF ou NEUTRE.\"\n",
        "                \"Réponds toujours sous forme de dictionnaire JSON avec les clés suivantes :\"\n",
        "                \"{\"\n",
        "                \"'sentiment': '<POSITIVE|NEGATIVE|NEUTRAL>',\"\n",
        "                \"'confidence': <float>,\"\n",
        "                \"'reason': '<explication du choix>'\"\n",
        "                \"}\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt\n",
        "            }\n",
        "        ],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stBN7W2NTtyd",
        "outputId": "9c0a06b2-76d4-4bca-9542-1e2065ed50af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': ' I am a model of an artificial intelligence designed to assist with a wide variety of tasks. I can'}]}]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(messages)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1zaq703Ttyd"
      },
      "source": [
        "# 2. **Mistral-Nemo-Instruct-2407** : [Lien vers le modèle](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2L9_uzMQTtye",
        "outputId": "fcc4490b-a3e9-4bc7-e9b5-1c7d3fadb8e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Quera\\Desktop\\Mistral-AI\\mistral\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Quera\\.cache\\huggingface\\hub\\models--mistralai--Mistral-Nemo-Instruct-2407. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Downloading shards:  60%|██████    | 3/5 [05:50<03:53, 116.80s/it]Error while downloading from https://cdn-lfs-us-1.hf.co/repos/e0/c5/e0c5526ca4c464d6b6bed6b017fafd0de19c67adc96c6d33d08056f22f6101a7/02a05716064ca298c767b7accf9aed9153f9e090eff4605b871de005ce7ce3a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00004-of-00005.safetensors%3B+filename%3D%22model-00004-of-00005.safetensors%22%3B&Expires=1734808500&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczNDgwODUwMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2UwL2M1L2UwYzU1MjZjYTRjNDY0ZDZiNmJlZDZiMDE3ZmFmZDBkZTE5YzY3YWRjOTZjNmQzM2QwODA1NmYyMmY2MTAxYTcvMDJhMDU3MTYwNjRjYTI5OGM3NjdiN2FjY2Y5YWVkOTE1M2Y5ZTA5MGVmZjQ2MDViODcxZGUwMDVjZTdjZTNhOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=QRn3P%7E8w6zmij8Pde1Bh-ghgg00zWyXfZLQ4Mys1kSjF2i5tkhLJ37mGWsFaC6V%7E4bYGUsYqR-APmRyDU9N0kp9y0Hk%7EePD6LdGHtHP09dpLVXte1BgpCt9VWiS%7EE1CfQpGNqrEBr7S3cthJ0TZxKsOupsgA%7EVUYkwHz%7Ez%7E-ebMiPw0Bx5PaNRu8VafJei5N9Ovsbnv2zdviYopPNaa5AJD8wWlSbBFKFkHvRynQfJ101VOcbCh3H0jJ97OOAZYvj3Hzy37hc%7EJ3e335haK4M4iFI-ROBqvd7WxIuKzUsNUhMCDXA2b6pLerDj6pDuTRJ2BnmBa2ozvzpnhX4t%7EkWw__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n",
            "Downloading shards:  80%|████████  | 4/5 [08:43<02:19, 139.33s/it]"
          ]
        }
      ],
      "source": [
        "# Use a pipeline as a high-level helper : Mistral-Nemo-Instruct-2407\n",
        "from transformers import pipeline\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-Nemo-Instruct-2407\")\n",
        "pipe(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiUYkNI9Ttye"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtz85BHTTtye"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".mistralai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
